{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "import sys\n",
    "import urllib  \n",
    "import re  \n",
    "import nltk\n",
    "import gensim\n",
    "\n",
    "from sklearn.manifold import TSNE, MDS, Isomap\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step 0:  Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def extract(json):\n",
    "    \"\"\"\n",
    "    input: json object\n",
    "    output: (cve description, cve published data, cve ID)\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return (json['cve']['description']['description_data'][0]['value'], \n",
    "                pd.to_datetime(json['publishedDate']), json['cve']['CVE_data_meta']['ID'])\n",
    "    except:\n",
    "        return (json['description']['description_data'][0]['value'], \n",
    "                pd.to_datetime(json['publishedDate']), json['cve']['CVE_data_meta']['ID'])\n",
    "\n",
    "    \n",
    "#replace_dots: get rid of any extension '.'s so they are not interpreted as full-stops\n",
    "def replace_dots(text):\n",
    "    try:\n",
    "        ind = text.index('.')\n",
    "        while ind < len(text)-1:\n",
    "            if not text[ind+1:ind+2] == ' ' and not text[ind+1:ind+2] == '\"' and not text[ind+1:ind+2] == '\\'':\n",
    "                text = text[:ind] + '_' + text[ind+1:]\n",
    "            try:\n",
    "                ind = ind+1 + text[ind+1:].index('.')\n",
    "            except:\n",
    "                break\n",
    "        return text\n",
    "    except:\n",
    "        return text\n",
    "\n",
    "    \n",
    "def remove_urls(text):\n",
    "    text = re.sub(r'\\[?\\S+\\]?\\(?https?://\\S+\\)?', '', text)\n",
    "    return text\n",
    "\n",
    "def remove_citations(text):\n",
    "    text = re.sub(r'\\(Citations?: \\S+\\)', '', text)\n",
    "    return text\n",
    "    \n",
    "    \n",
    "#clean up the text\n",
    "def remove_chars(text):\n",
    "    to_remove = \"This technique has been deprecated. Please see ATT&CK's Initial Access and Execution tactics for replacement techniques.\"\n",
    "    text = text.replace(to_remove,'')\n",
    "    text = re.sub('<[^>]*>', '', text.lower()).strip()\n",
    "    text = re.sub('[^a-zA-Z\\'\\_]', ' ', text.lower())\n",
    "    return text\n",
    "\n",
    "def clean_text(text):\n",
    "    clean = remove_citations(text)\n",
    "    clean = remove_urls(clean)\n",
    "    clean = replace_dots(clean)\n",
    "    clean = remove_chars(clean)\n",
    "    return clean\n",
    "\n",
    "\n",
    "##****************MITRE Functions****************##\n",
    "\n",
    "def get_all_software(src):\n",
    "    filts = [\n",
    "        [Filter('type', '=', 'malware')],\n",
    "        [Filter('type', '=', 'tool')]\n",
    "    ]\n",
    "    return list(chain.from_iterable(\n",
    "        src.query(f) for f in filts\n",
    "    ))\n",
    "\n",
    "def get_all_techniques(src):\n",
    "    filt = [Filter('type', '=', 'attack-pattern')]\n",
    "    return src.query(filt)\n",
    "    \n",
    "def get_technique_by_name(src, name):\n",
    "    filt = [\n",
    "        Filter('type', '=', 'attack-pattern'),\n",
    "        Filter('name', '=', name)\n",
    "    ]\n",
    "    return src.query(filt)\n",
    "\n",
    "def get_techniques_by_content(src, content):\n",
    "    techniques = get_all_techniques(src)\n",
    "    return [\n",
    "        tech for tech in techniques\n",
    "        if content.lower() in tech.description.lower()\n",
    "    ]\n",
    "\n",
    "def get_mitigations_by_technique(src, tech_stix_id):\n",
    "    relations = src.relationships(tech_stix_id, 'mitigates', target_only=True)\n",
    "    return src.query([\n",
    "        Filter('type', '=', 'course-of-action'),\n",
    "        Filter('id', 'in', [r.source_ref for r in relations])\n",
    "    ])\n",
    "\n",
    "def get_group_by_technique(src, tech_stix_id):\n",
    "    relations = src.relationships(tech_stix_id, 'uses', target_only=True)\n",
    "    return src.query([\n",
    "        Filter('type', '=', 'intrusion-set'),\n",
    "        Filter('id', 'in', [r.source_ref for r in relations])\n",
    "    ])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step 1: Extract Data\n",
    "\n",
    "- Extract data from compressed files from NIST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MITRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from stix2 import FileSystemSource\n",
    "from stix2 import Filter\n",
    "\n",
    "fs = FileSystemSource('enterprise-attack')\n",
    "filt = Filter('type', '=', 'attack-pattern')\n",
    "techniques_ent = fs.query([filt])\n",
    "\n",
    "fs = FileSystemSource('pre-attack')\n",
    "filt = Filter('type', '=', 'attack-pattern')\n",
    "techniques_pre = fs.query([filt])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NIST NVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#read compressed files downloaded from NIST NVD \n",
    "\n",
    "mypath = 'nist_historical'\n",
    "onlyfiles = [f for f in os.listdir(mypath) if os.path.isfile(os.path.join(mypath, f))]\n",
    "onlyfiles.remove('.DS_Store')\n",
    "\n",
    "\n",
    "blobs = {}\n",
    "\n",
    "for fname in onlyfiles:\n",
    "    with gzip.open(mypath+'/'+fname) as f:\n",
    "        blobs[fname] = json.load(f)\n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step 2: Dedupe + Clean Data\n",
    "\n",
    "- Clean up ATT&CK data + add to dataframe\n",
    "- Dedupe CVE entries to account for any repetitions within the NIST compressed folders + add to dataframe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## MITRE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "ent_dict = {obj['id']: (obj['name'], obj['description']) for obj in techniques_ent}\n",
    "pre_dict = {obj['id']: (obj['name'], obj['description']) for obj in techniques_pre}\n",
    "\n",
    "ent_df = pd.DataFrame({'attack_id':ent_dict.keys(), 'values': ent_dict.values()})\n",
    "pre_df = pd.DataFrame({'attack_id':pre_dict.keys(), 'values': pre_dict.values()})\n",
    "\n",
    "ent_df['type'] = ['ent_attack']*ent_df.shape[0]\n",
    "pre_df['type'] = ['pre_attack']*pre_df.shape[0]\n",
    "\n",
    "techniques_df = pd.concat([ent_df, pre_df], axis=0)\n",
    "techniques_df['attack_name'] = techniques_df['values'].apply(lambda x: x[0].encode('utf-8').strip())\n",
    "techniques_df['attack_description'] = techniques_df['values'].apply(lambda x: x[1].encode('utf-8').strip())\n",
    "techniques_df.dropna(inplace=True)\n",
    "techniques_df['cleanText'] = techniques_df['attack_description'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## NIST NVD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "#cve_descs stores all of the cve descriptions from each JSON object\n",
    "cve_descs = {}\n",
    "\n",
    "for key in blobs.keys():\n",
    "    for n, report_meat in enumerate(blobs[key]['CVE_Items']):\n",
    "        desc, date, cve_id = extract(report_meat)\n",
    "        cve_descs[cve_id] = (desc,date)\n",
    "        \n",
    "#add all the values to a 3rd dataframe\n",
    "cve_df = pd.DataFrame({\"cveID\":cve_descs.keys(), \"cveDescription\": [v[0] for v in cve_descs.values()],\n",
    "                               \"publishedTime\": [v[1] for v in cve_descs.values()]})\n",
    "\n",
    "# final deduping of all 3 dataframes\n",
    "all_zip = zip(cve_df['cveID'], cve_df['cveDescription']) + zip(techniques_df['attack_id'],techniques_df['attack_description'])\n",
    "final_dict = {key: value for key,value in all_zip}\n",
    "\n",
    "# # add it to a datframe\n",
    "cve_df['cleanText'] = cve_df['cveDescription'].apply(lambda x: replace_dots(x))\n",
    "cve_df['cleanText'] = cve_df['cleanText'].apply(lambda x: clean_text(x))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step 3: Create Named Tuples\n",
    "\n",
    "Gensim requires NamedTuples for processing documents. NamedTuples have the added convenience of associating tags with documents so it's easy to join documents back to their associated metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from gensim.models.doc2vec import TaggedDocument\n",
    "from collections import namedtuple\n",
    "\n",
    "# this data object class suffices as a `TaggedDocument` (with `words` and `tags`) \n",
    "# plus adds other state helpful for our later evaluation/reporting\n",
    "Document = namedtuple('TaggedDocument', 'words tags object_type')\n",
    "\n",
    "alldocs = []\n",
    "for row_id, row in zip(techniques_df['attack_id'],techniques_df['cleanText']):\n",
    "    words = gensim.utils.to_unicode(row).split()\n",
    "    tags = [row_id]\n",
    "    object_type = 'ATTACK'\n",
    "    alldocs.append(Document(words, tags, object_type))\n",
    "    \n",
    "for row_id, row in zip(cve_df['cveID'],cve_df['cleanText']):\n",
    "    words = gensim.utils.to_unicode(row).split()\n",
    "    tags = [row_id] # 'tags = [tokens[0]]' would also work at extra memory cost\n",
    "    object_type = 'CVE'\n",
    "    alldocs.append(Document(words, tags, object_type))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step 4: Set up Doc2Vec Training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "We approximate the experiment of Le & Mikolov [\"Distributed Representations of Sentences and Documents\"](http://cs.stanford.edu/~quocle/paragraph_vector.pdf) with guidance from Mikolov's [example go.sh](https://groups.google.com/d/msg/word2vec-toolkit/Q49FIrNOQRo/J6KG8mUj45sJ):\n",
    "\n",
    "`./word2vec -train ../alldata-id.txt -output vectors.txt -cbow 0 -size 100 -window 10 -negative 5 -hs 0 -sample 1e-4 -threads 40 -binary 0 -iter 20 -min-count 1 -sentence-vectors 1`\n",
    "\n",
    "We vary the following parameter choices:\n",
    "* 100-dimensional vectors, as the 400-d vectors of the paper take a lot of memory and, in our tests of this task, don't seem to offer much benefit\n",
    "* Similarly, frequent word subsampling seems to decrease sentiment-prediction accuracy, so it's left out\n",
    "* `cbow=0` means skip-gram which is equivalent to the paper's 'PV-DBOW' mode, matched in gensim with `dm=0`\n",
    "* Added to that DBOW model are two DM models, one which averages context vectors (`dm_mean`) and one which concatenates them (`dm_concat`, resulting in a much larger, slower, more data-hungry model)\n",
    "* A `min_count=2` saves quite a bit of model memory, discarding only words that appear in a single doc (and are thus no more expressive than the unique-to-each doc vectors themselves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Doc2Vec(dbow,d100,n5,mc10,t8) vocabulary scanned & state initialized\n",
      "Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc10,t8) vocabulary scanned & state initialized\n",
      "Doc2Vec(dm/c,d100,n5,w5,mc10,t8) vocabulary scanned & state initialized\n"
     ]
    }
   ],
   "source": [
    "# %%time\n",
    "from gensim.models import Doc2Vec\n",
    "import gensim.models.doc2vec\n",
    "from collections import OrderedDict\n",
    "import multiprocessing\n",
    "\n",
    "cores = multiprocessing.cpu_count()\n",
    "assert gensim.models.doc2vec.FAST_VERSION > -1, \"This will be painfully slow otherwise\"\n",
    "\n",
    "simple_models = [\n",
    "    # PV-DBOW plain\n",
    "    Doc2Vec(dm=0, vector_size=100, negative=5, hs=0, min_count=10, sample=0, \n",
    "            epochs=20, workers=cores),\n",
    "    # PV-DM w/ default averaging; a higher starting alpha may improve CBOW/PV-DM modes\n",
    "    Doc2Vec(dm=1, vector_size=100, window=10, negative=5, hs=0, min_count=10, sample=0, \n",
    "            epochs=20, workers=cores, alpha=0.05, comment='alpha=0.05'),\n",
    "    # PV-DM w/ concatenation - big, slow, experimental mode\n",
    "    # window=5 (both sides) approximates paper's apparent 10-word total window size\n",
    "    Doc2Vec(dm=1, dm_concat=1, vector_size=100, window=5, negative=5, hs=0, min_count=10, sample=0, \n",
    "            epochs=20, workers=cores),\n",
    "]\n",
    "\n",
    "for model in simple_models:\n",
    "    model.build_vocab(alldocs)\n",
    "    print(\"%s vocabulary scanned & state initialized\" % model)\n",
    "\n",
    "models_by_name = OrderedDict((str(model), model) for model in simple_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "from random import shuffle\n",
    "doc_list = alldocs[:]  \n",
    "shuffle(doc_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Doc2Vec(dbow,d100,n5,mc10,t8)\n",
      "CPU times: user 2min 56s, sys: 37.4 s, total: 3min 34s\n",
      "Wall time: 1min 50s\n",
      "Training Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc10,t8)\n",
      "CPU times: user 4min 7s, sys: 51.1 s, total: 4min 58s\n",
      "Wall time: 2min 20s\n",
      "Training Doc2Vec(dm/c,d100,n5,w5,mc10,t8)\n",
      "CPU times: user 6min 50s, sys: 51 s, total: 7min 41s\n",
      "Wall time: 2min 22s\n"
     ]
    }
   ],
   "source": [
    "for model in simple_models: \n",
    "    print(\"Training %s\" % model)\n",
    "    %time model.train(doc_list, total_examples=len(doc_list), epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "slideshow": {
     "slide_type": "skip"
    }
   },
   "outputs": [],
   "source": [
    "word_models = simple_models[:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Step 5: Run with it!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## How similar are 'similar' words?\n",
    " Play around with words by changing the variable 'word'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "most similar words for 'execute' (25862 occurences)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table><tr><th>Doc2Vec(dbow,d100,n5,mc10,t8)</th><th>Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc10,t8)</th><th>Doc2Vec(dm/c,d100,n5,w5,mc10,t8)</th></tr><tr><td>[(u'mdm', 0.4347737431526184),<br>\n",
       "(u'activematrix', 0.344107985496521),<br>\n",
       "(u'affected', 0.3438035845756531),<br>\n",
       "(u'uses', 0.31682759523391724),<br>\n",
       "(u'caused', 0.3130490779876709),<br>\n",
       "(u'awa', 0.31220555305480957),<br>\n",
       "(u'libvpx', 0.3115987181663513),<br>\n",
       "(u'gems', 0.31055089831352234),<br>\n",
       "(u'algorithms', 0.3047991991043091),<br>\n",
       "(u'_server', 0.3032001256942749),<br>\n",
       "(u'xserver', 0.30311456322669983),<br>\n",
       "(u'trigger', 0.30237576365470886),<br>\n",
       "(u'qualified', 0.29969215393066406),<br>\n",
       "(u'realplayer', 0.2984297275543213),<br>\n",
       "(u'co', 0.2973718047142029),<br>\n",
       "(u'share', 0.29577529430389404),<br>\n",
       "(u'grails', 0.29440414905548096),<br>\n",
       "(u'tries', 0.29240185022354126),<br>\n",
       "(u'h_', 0.2895732522010803),<br>\n",
       "(u'installers', 0.2866915762424469)]</td><td>[(u'run', 0.8072041273117065),<br>\n",
       "(u'inject', 0.6828826665878296),<br>\n",
       "(u'read', 0.6366456747055054),<br>\n",
       "(u'execution', 0.6291384100914001),<br>\n",
       "(u'overwrite', 0.5641766786575317),<br>\n",
       "(u'executing', 0.535063624382019),<br>\n",
       "(u'executed', 0.48166775703430176),<br>\n",
       "(u'create', 0.48140668869018555),<br>\n",
       "(u'perform', 0.43708884716033936),<br>\n",
       "(u'write', 0.42084765434265137),<br>\n",
       "(u'signing', 0.4109715521335602),<br>\n",
       "(u'delete', 0.4091721475124359),<br>\n",
       "(u'download', 0.40684735774993896),<br>\n",
       "(u'load', 0.3937813937664032),<br>\n",
       "(u'directories', 0.3863033652305603),<br>\n",
       "(u'change', 0.3854135572910309),<br>\n",
       "(u'e_g_', 0.37903088331222534),<br>\n",
       "(u'submit', 0.37315118312835693),<br>\n",
       "(u'embed', 0.37288904190063477),<br>\n",
       "(u'send', 0.3692713975906372)]</td><td>[(u'run', 0.5840804576873779),<br>\n",
       "(u'invoke', 0.5547510385513306),<br>\n",
       "(u'inject', 0.5293723344802856),<br>\n",
       "(u'accomplish', 0.48468339443206787),<br>\n",
       "(u'constrain', 0.4820373058319092),<br>\n",
       "(u'isolate', 0.4772493839263916),<br>\n",
       "(u'executing', 0.47279685735702515),<br>\n",
       "(u'siclock', 0.46621909737586975),<br>\n",
       "(u'deserialize', 0.462011456489563),<br>\n",
       "(u'collateral', 0.4559507369995117),<br>\n",
       "(u'achieve', 0.4514831602573395),<br>\n",
       "(u'evaluated', 0.4508994221687317),<br>\n",
       "(u'hooked', 0.4488168954849243),<br>\n",
       "(u'forensics', 0.44768086075782776),<br>\n",
       "(u'ntdll_', 0.44571202993392944),<br>\n",
       "(u'nnmrptconfig_exe', 0.4428020417690277),<br>\n",
       "(u'matrimonial', 0.4416455030441284),<br>\n",
       "(u'nlst', 0.4411974549293518),<br>\n",
       "(u'forge', 0.44059404730796814),<br>\n",
       "(u'replaced', 0.4352682828903198)]</td></tr></table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "from IPython.display import HTML\n",
    "# pick a random word with a suitable number of occurences\n",
    "while True:\n",
    "    word = random.choice(word_models[0].wv.index2word)\n",
    "    if word_models[0].wv.vocab[word].count > 200:\n",
    "        break\n",
    "# or uncomment below line, to just pick a word from the relevant domain:\n",
    "word = 'execute'\n",
    "similars_per_model = [str(model.wv.most_similar(word, topn=20)).replace('), ','),<br>\\n') for model in word_models]\n",
    "similar_table = (\"<table><tr><th>\" +\n",
    "    \"</th><th>\".join([str(model) for model in word_models]) + \n",
    "    \"</th></tr><tr><td>\" +\n",
    "    \"</td><td>\".join(similars_per_model) +\n",
    "    \"</td></tr></table>\")\n",
    "print(\"most similar words for '%s' (%d occurences)\" % (word, simple_models[0].wv.vocab[word].count))\n",
    "HTML(similar_table)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Compare different models by printing closest documents\n",
    "The randomizer picks any document at random and prints the documents closest to it. The next two blocks use PV-DM and PV-DBOW respectively"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### PV-DM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET (attack-pattern--0649fc36-72a0-40a0-a2f9-3fc7e3231ad6): «Callbacks are malware communications seeking instructions. An adversary will test their malware to ensure the appropriate instructions are conveyed and the callback software can be reached. (Citation: LeeBeaconing)»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(\"alpha=0.05\",dm/m,d100,n5,w10,mc10,t8):\n",
      "\n",
      "MOST (u'CVE-2018-7053', 0.6692964434623718): «An issue was discovered in Irssi before 1.0.7 and 1.1.x before 1.1.1. There is a use-after-free when SASL messages are received in an unexpected order.»\n",
      "\n",
      "MEDIAN (u'CVE-2010-0019', 0.4216613471508026): «Microsoft Silverlight 3 before 3.0.50611.0 on Windows, and before 3.0.41130.0 on Mac OS X, does not properly handle pointers, which allows remote attackers to execute arbitrary code or cause a denial of service (memory corruption and framework outage) via a crafted web site, aka \"Microsoft Silverlight Memory Corruption Vulnerability.\"»\n",
      "\n",
      "LEAST (u'CVE-2017-12170', -0.17178192734718323): «Downstream version 1.0.46-1 of pure-ftpd as shipped in Fedora was vulnerable to packaging error due to which the original configuration was ignored after update and service started running with default configuration. This has security implications because of overriding security-related configuration. This issue doesn't affect upstream version of pure-ftpd.»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "doc_id = np.random.randint(397)  # pick random doc, re-run cell for more examples\n",
    "model = simple_models[1]  # and a random model\n",
    "sims = model.docvecs.most_similar(doc_id, topn=model.docvecs.count)  # get *all* similar documents\n",
    "print(u'TARGET (%s): «%s»\\n' % (alldocs[doc_id][1][0], final_dict[alldocs[doc_id][1][0]]))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], final_dict[sims[index][0]]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "### PV-DBOW"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "TARGET (CVE-2017-5161): «An issue was discovered in Sielco Sistemi Winlog Lite SCADA Software, versions prior to Version 3.02.01, and Winlog Pro SCADA Software, versions prior to Version 3.02.01. An uncontrolled search path element (DLL Hijacking) vulnerability has been identified. Exploitation of this vulnerability could give an attacker access to the system with the same level of privilege as the application that utilizes the malicious DLL.»\n",
      "\n",
      "SIMILAR/DISSIMILAR DOCS PER MODEL Doc2Vec(dbow,d100,n5,mc10,t8):\n",
      "\n",
      "MOST (u'CVE-2018-14812', 0.9075496196746826): «An uncontrolled search path element (DLL Hijacking) vulnerability has been identified in Fuji Electric Energy Savings Estimator versions V.1.0.2.0 and prior. Exploitation of this vulnerability could give an attacker access to the system with the same level of privilege as the application that utilizes the malicious DLL.»\n",
      "\n",
      "MEDIAN (u'CVE-2008-2834', 0.20582585036754608): «SQL injection vulnerability in projects.php in Scientific Image DataBase 0.41 allows remote attackers to execute arbitrary SQL commands via the id parameter.»\n",
      "\n",
      "LEAST (u'CVE-2017-14495', -0.2229628562927246): «Memory leak in dnsmasq before 2.78, when the --add-mac, --add-cpe-id or --add-subnet option is specified, allows remote attackers to cause a denial of service (memory consumption) via vectors involving DNS response creation.»\n",
      "\n"
     ]
    }
   ],
   "source": [
    "  # pick random doc, re-run cell for more examples\n",
    "## 7189, 41355, 29820\n",
    "doc_id = 78030\n",
    "# doc_id = np.random.randint(simple_models[1].docvecs.count)  # pick random doc, re-run cell for more examples\n",
    "model = simple_models[0]  # and a random model\n",
    "sims = model.docvecs.most_similar(doc_id, topn=model.docvecs.count)  # get *all* similar documents\n",
    "print(u'TARGET (%s): «%s»\\n' % (alldocs[doc_id][1][0], final_dict[alldocs[doc_id][1][0]]))\n",
    "print(u'SIMILAR/DISSIMILAR DOCS PER MODEL %s:\\n' % model)\n",
    "for label, index in [('MOST', 0), ('MEDIAN', len(sims)//2), ('LEAST', len(sims) - 1)]:\n",
    "    print(u'%s %s: «%s»\\n' % (label, sims[index], final_dict[sims[index][0]]))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Clusters\n",
    "- Create a 100 clusters\n",
    "- Explore each by changing the cluster index in the second cell"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "NUM_CLUSTERS = 100\n",
    "\n",
    "docvecs = []\n",
    "keys = []\n",
    "for doc_id in range(len(model.docvecs)):\n",
    "    keys.append(alldocs[doc_id][1][0])\n",
    "    docvecs.append(model.docvecs[doc_id])\n",
    "docvecs = np.array(docvecs)\n",
    "\n",
    "kclusterer = KMeans(n_clusters=NUM_CLUSTERS, random_state=333, max_iter=100)\n",
    "assigned_clusters = kclusterer.fit(docvecs)\n",
    "\n",
    "#add to dictionary\n",
    "key_cluster = {}\n",
    "for key,cluster in zip(keys, assigned_clusters.labels_):\n",
    "    if cluster in key_cluster:\n",
    "        key_cluster[cluster].append(key)\n",
    "    else: \n",
    "        key_cluster[cluster] = [key]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CVE-2014-3219  >>  fish before 2.1.1 allows local users to write to arbitrary files via a symlink attack on (1) /tmp/fishd.log.%s, (2) /tmp/.pac-cache.$USER, (3) /tmp/.yum-cache.$USER, or (4) /tmp/.rpm-cache.$USER.\n",
      "\n",
      "CVE-2012-0426  >>  Race condition in sap_suse_cluster_connector before 1.0.0-0.8.1 in SUSE Linux Enterprise for SAP Applications 11 SP2 allows local users to have an unspecified impact via vectors related to a tmp/ directory.\n",
      "\n",
      "CVE-2012-0420  >>  zypp-refresh-wrapper in SUSE Zypper before 1.3.20 and 1.6.x before 1.6.166 allows local users to create files in arbitrary directories, or possibly have unspecified other impact, via a pathname in the ZYPP_LOCKFILE_ROOT environment variable.\n",
      "\n",
      "CVE-2017-12414  >>  Format Factory 4.1.0 has a DLL Hijacking Vulnerability because an untrusted search path is used for msimg32.dll, WindowsCodecs.dll, and dwmapi.dll.\n",
      "\n",
      "CVE-2017-11160  >>  Multiple untrusted search path vulnerabilities in installer in Synology Assistant before 6.1-15163 on Windows allows local attackers to execute arbitrary code and conduct DLL hijacking attack via a Trojan horse (1) shfolder.dll, (2) ntmarta.dll, (3) secur32.dll or (4) dwmapi.dll file in the current working directory.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#change cluster number to see any random cluster\n",
    "cluster = 5\n",
    "for i in key_cluster[cluster][:5]:\n",
    "    print i, \" >> \", final_dict[i]\n",
    "    print"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "subslide"
    }
   },
   "source": [
    "## Find Similar ATT&CK Pattern or CVE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "slideshow": {
     "slide_type": "fragment"
    }
   },
   "outputs": [],
   "source": [
    "def find_similar(row_id, match_with, alldocs=alldocs, final_dict=final_dict, model=model):\n",
    "    \"\"\"\n",
    "    row_id: attack-pattern id or CVE id\n",
    "    match_with: 1=CVE, 2=attack\n",
    "    \"\"\"\n",
    "    ind = {1:'CVE', 2:'attack-pattern'}\n",
    "    doc_id = [i for i in range(len(alldocs)) if alldocs[i][1][0] == row_id]\n",
    "    sims = model.docvecs.most_similar(doc_id, topn=model.docvecs.count)\n",
    "    sim_row_id = [i for i in sims if i[0][:3] == ind[match_with][:3]][0] #this ensures the top 1\n",
    "    print(\"**You asked for a(n) %s closest to the %s which is described as:**\" %(ind[match_with], row_id))\n",
    "    print\n",
    "    print(final_dict[row_id])\n",
    "    print\n",
    "    print(\"**The closest %s to %s is %s and is described as:**\"%(ind[match_with], row_id, sim_row_id[0]))\n",
    "    print\n",
    "    print(final_dict[sim_row_id[0]])\n",
    "    print\n",
    "    print(\"**Their similarity score is: %0.4f**\"%sim_row_id[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**You asked for a(n) CVE closest to the attack-pattern--aa8bfbc9-78dc-41a4-a03b-7453e0fdccda which is described as:**\n",
      "\n",
      "macOS and OS X use a common method to look for required dynamic libraries (dylib) to load into a program based on search paths. Adversaries can take advantage of ambiguous paths to plant dylibs to gain privilege escalation or persistence.\n",
      "\n",
      "A common method is to see what dylibs an application uses, then plant a malicious version with the same name higher up in the search path. This typically results in the dylib being in the same folder as the application itself. (Citation: Writing Bad Malware for OSX) (Citation: Malware Persistence on OS X)\n",
      "\n",
      "If the program is configured to run at a higher privilege level than the current user, then when the dylib is loaded into the application, the dylib will also run at that elevated level. This can be used by adversaries as a privilege escalation technique.\n",
      "\n",
      "**The closest CVE to attack-pattern--aa8bfbc9-78dc-41a4-a03b-7453e0fdccda is CVE-2017-6329 and is described as:**\n",
      "\n",
      "Symantec VIP Access for Desktop prior to 2.2.4 can be susceptible to a DLL Pre-Loading vulnerability. These types of issues occur when an application looks to call a DLL for execution and an attacker provides a malicious DLL to use instead. Depending on how the application is configured, the application will generally follow a specific search path to locate the DLL. The exploitation of the vulnerability manifests as a simple file write (or potentially an over-write) which results in a foreign executable running under the context of the application.\n",
      "\n",
      "**Their similarity score is: 0.6803**\n"
     ]
    }
   ],
   "source": [
    "find_similar('attack-pattern--aa8bfbc9-78dc-41a4-a03b-7453e0fdccda', 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
